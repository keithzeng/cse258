{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "#reading data\n",
    "rawdata=list(readGz(\"reviews_Electronics_5.json.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def pad(c): return ' '+c\n",
    "remove_table = str.maketrans({}.fromkeys(string.punctuation))\n",
    "keep_table = str.maketrans({pun:pad(pun) for pun in string.punctuation})\n",
    "table={True: remove_table, False:keep_table}\n",
    "\n",
    "#clean the data before fitting\n",
    "def clean(text,table,remove):\n",
    "    return text.lower().translate(table[remove])\n",
    "\n",
    "data=rawdata\n",
    "for d in data:\n",
    "    d['reviewText']=clean(d['reviewText'],table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:20000]\n",
    "import pandas as pd\n",
    "df=pd.DataFrame.from_dict(data)\n",
    "df.drop(columns=['helpful','reviewTime','reviewerID','reviewerName',\n",
    "         'summary','unixReviewTime'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1872416244052335\n",
      "0.7448179899762848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer(max_features=2000)\n",
    "X=vectorizer.fit_transform(df.reviewText)\n",
    "y=df.overall\n",
    "clf=linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X.toarray(), y)\n",
    "predictions=clf.predict(X)\n",
    "print(mse(y,predictions))\n",
    "\n",
    "clf=linear_model.Ridge(1.0, fit_intercept=True)\n",
    "clf.fit(X.toarray(), y)\n",
    "predictions=clf.predict(X)\n",
    "print(mse(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3945919324032563\n",
      "0.6884491678880381\n"
     ]
    }
   ],
   "source": [
    "vectorizer=TfidfVectorizer(max_features=2000)\n",
    "X=vectorizer.fit_transform(df.reviewText)\n",
    "y=df.overall\n",
    "clf=linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X.toarray(), y)\n",
    "predictions=clf.predict(X)\n",
    "print(mse(y,predictions))\n",
    "\n",
    "clf=linear_model.Ridge(1.0, fit_intercept=True)\n",
    "clf.fit(X.toarray(), y)\n",
    "predictions=clf.predict(X)\n",
    "print(mse(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3975678867929218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline=Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', linear_model.Ridge()),\n",
    "])\n",
    "pipeline.set_params(vect__max_features=2000)\n",
    "pipeline.set_params(clf__alpha=1)\n",
    "pipeline.set_params(clf__fit_intercept=False)\n",
    "pipeline.fit(df.reviewText,y)\n",
    "predictions=pipeline.predict(df.reviewText)\n",
    "print(mse(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'clf__alpha':[1,10,100],\n",
    "       'clf__fit_intercept':[True],\n",
    "       'vect__max_features': [1000,2000,3000],\n",
    "       'vect__stop_words':['english',None],\n",
    "       'vect__ngram_range':[(1,1),(1,2),(1,3)]\n",
    "       }\n",
    "grid_search=GridSearchCV(pipeline, params,cv=5,verbose=1,\n",
    "                         scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...t_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__alpha': [0.1, 1, 10, 100], 'clf__fit_intercept': [True], 'vect__max_features': [1000, 2000], 'vect__stop_words': ['english', None], 'vect__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(df.reviewText,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9093955528825496"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 1,\n",
       " 'clf__fit_intercept': True,\n",
       " 'vect__max_features': 2000,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': None}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
